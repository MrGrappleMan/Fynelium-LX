# 

[model]
cycle = 20

# better prediction accuracy
usecorrelation = true

minsize = 2000000

# The following control how much memory preload is allowed to use
# for preloading in each cycle.  All values are percentages and are
# clamped to -100 to 100.
#
# The total memory preload uses for prefetching is then computed using
# the following formulae:
#
# 	max (0, TOTAL * memtotal + FREE * memfree) + CACHED * memcached
# where TOTAL, FREE, and CACHED are the respective values read at
# runtime from /proc/meminfo. And this is only physical RAM w/o swap space

# Originally planned to keep -2% of total memory always free for immediate memory demands by setting to "-2"
# but memfree does it relative(to the correct contextof actually free memory) good enough
# I originally used this blindly, but this can just cause OOM more frequently without proper scaling once memory starts getting consumed.
memtotal = 0
# Use 85% percent of free memory available for preloading
memfree = 85
# We don't want to interfere with memory already in cache
memcached = 0

[system]

# Intelligence
doscan = true
dopredict = true

# Safe
autosave = 600

# ? To be decided
mapprefix = /usr/;/lib;/var/cache/;!/
exeprefix = !/usr/sbin/;!/usr/local/sbin/;/usr/;!/

# Parallel readahead supposedly gives a better I/O
# performance as it allows the kernel to batch several I/O requests
# of nearby blocks
processes = 128

# Sort based on disk block
sortstrategy = 3
